# LLM Provider Configuration
# Copy this file to .env and update with your API keys

# Active provider (choose one):
# ollama/llama3.2, ollama/qwen2.5, openai/gpt-4o-mini, anthropic/claude-3-5-haiku
ACTIVE_PROVIDER=ollama/llama3.2

# Cloud API Keys (optional if using cloud providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Local Provider URLs
OLLAMA_BASE_URL=http://localhost:11434
LM_STUDIO_URL=http://localhost:1234

# TTS Configuration
TTS_HOST=localhost
TTS_PORT=8000

# Security Configuration
# Generate secure JWT secret with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
JWT_SECRET=your_secure_64_char_hex_string_here

# CORS - Comma-separated list of allowed origins for production
ALLOWED_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# Environment
NODE_ENV=development
