# LLM Provider Configuration
# Copy this file to .env and update with your API keys

# Active provider (choose one):
# ollama/llama3.2, ollama/qwen2.5, openai/gpt-4o-mini, anthropic/claude-3-5-haiku
ACTIVE_PROVIDER=ollama/llama3.2

# Cloud API Keys (optional if using cloud providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Local Provider URLs
OLLAMA_BASE_URL=http://localhost:11434
LM_STUDIO_URL=http://localhost:1234

# TTS Configuration
TTS_HOST=localhost
TTS_PORT=8000