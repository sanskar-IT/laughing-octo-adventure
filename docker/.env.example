# AI Companion - Environment Configuration
# Copy this file to .env and fill in your values
# DO NOT commit .env to git!

# ==========================================
# SERVICE PORTS
# ==========================================
BACKEND_PORT=3000
TTS_PORT=4000
OLLAMA_PORT=5000
FRONTEND_PORT=6000
NGINX_PORT=8080
NGINX_SSL_PORT=8443

# ==========================================
# SECURITY
# ==========================================
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
JWT_SECRET=your_64_character_hex_secret_here_change_this_in_production

# ==========================================
# LLM CONFIGURATION (Hybrid)
# ==========================================
# Primary: Local Ollama model (fast, private)
PRIMARY_PROVIDER=ollama/qwen2.5:3b

# Fallback chain (comma-separated, in priority order)
# Options: groq/..., openrouter/..., openai/..., anthropic/...
FALLBACK_PROVIDERS=groq/llama-3.2-3b,openrouter/meta-llama/llama-3.2-3b-instruct

# ==========================================
# CLOUD LLM API KEYS (for fallback)
# ==========================================
# Groq - Fast inference, free tier available
# Get key at: https://console.groq.com/
GROQ_API_KEY=

# OpenRouter - Cheapest option, aggregates multiple providers
# Get key at: https://openrouter.ai/
OPENROUTER_API_KEY=

# OpenAI - Most reliable, paid only
# Get key at: https://platform.openai.com/
OPENAI_API_KEY=

# Anthropic - High quality, paid only
# Get key at: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# ==========================================
# OLLAMA CONFIGURATION
# ==========================================
# Number of GPU layers to use (adjust based on VRAM)
# RTX 4050 (6GB): ~35 layers for 3B model
OLLAMA_GPU_LAYERS=35

# Keep model loaded in memory (prevents cold start)
OLLAMA_KEEP_ALIVE=30m

# ==========================================
# CORS SETTINGS
# ==========================================
# Allowed origins for API requests
ALLOWED_ORIGINS=http://localhost:8080,http://localhost:3000

# ==========================================
# LOGGING
# ==========================================
# Levels: debug, info, warning, error
LOG_LEVEL=info

# ==========================================
# DATABASE
# ==========================================
# SQLite database path (inside container)
DATABASE_URL=sqlite:///app/data/conversations.db

# ==========================================
# TTS SETTINGS
# ==========================================
TTS_ENGINE=edge-tts
TTS_VOICE=en-US-AriaNeural
TTS_SPEED=1.0

# ==========================================
# MEMORY SETTINGS
# ==========================================
# Maximum context window size
MAX_CONTEXT_WINDOW=4096
# Number of past messages to retrieve
RETRIEVAL_LIMIT=5

# ==========================================
# DEVELOPMENT SETTINGS
# ==========================================
# Enable hot reload (dev only)
HOT_RELOAD=true
# Enable debug mode
DEBUG=false
